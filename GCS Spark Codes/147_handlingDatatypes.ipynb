{"cells": [{"cell_type": "code", "execution_count": 3, "id": "dc44cb4f-b205-4811-bf15-b2ec26de7720", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/06/08 10:06:41 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('Data Types').getOrCreate()"}, {"cell_type": "code", "execution_count": 9, "id": "62092a30-606c-4e1b-ba72-03c71c1155d9", "metadata": {"tags": []}, "outputs": [], "source": "data = [\n    (1, \"John Doe\", \"Bangalore\", \"15-02-2025\", \"152.75\", \"True\"),\n    (12, \"Jane Smith\", \"Delhi\", \"2023-05-20\", \"869.90\", \"False\"),\n    (3, \"Robert Brown\", \"Mumbai\", \"InvalidDate\", \"200.00\", \"True\"),\n    (14, \"Linda White\", \"Kolkata\", \"2023-02-29\", None, \"yes\"),  # Feb 29 invalid in 2023\n    (5, \"Mike Green\", \"Chennai\", \"2023-08-10\", \"NaN\", \"1\"),  # NaN needs handling\n    (6, \"Sarah Blue\", \"Hyderabad\", \"InvalidDate\", \"300.40\", \"No\")\n]\ncolumns = ['id', 'name', 'city', 'date', 'amount', 'is_active']\ndf = spark.createDataFrame(data, schema = columns)"}, {"cell_type": "code", "execution_count": 10, "id": "d33a87e4-c481-40c8-8249-26d62f2d500d", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+---+------------+---------+-----------+------+---------+\n| id|        name|     city|       date|amount|is_active|\n+---+------------+---------+-----------+------+---------+\n|  1|    John Doe|Bangalore| 15-02-2025|152.75|     True|\n| 12|  Jane Smith|    Delhi| 2023-05-20|869.90|    False|\n|  3|Robert Brown|   Mumbai|InvalidDate|200.00|     True|\n| 14| Linda White|  Kolkata| 2023-02-29|  NULL|      yes|\n|  5|  Mike Green|  Chennai| 2023-08-10|   NaN|        1|\n|  6|  Sarah Blue|Hyderabad|InvalidDate|300.40|       No|\n+---+------------+---------+-----------+------+---------+\n\n"}], "source": "df.show()"}, {"cell_type": "code", "execution_count": 11, "id": "a84a5d79-26be-4740-8e6e-d85785202117", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- city: string (nullable = true)\n |-- date: string (nullable = true)\n |-- amount: string (nullable = true)\n |-- is_active: string (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "code", "execution_count": null, "id": "a7507b17-f6b9-43e3-8b67-714e8175758b", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}