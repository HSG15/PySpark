{"cells": [{"cell_type": "code", "execution_count": 1, "id": "54f3b82b-c4e4-4023-b369-8f19d140bb4f", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/06/11 15:27:11 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('groupByKey_vs_reduceByKey').getOrCreate()"}, {"cell_type": "code", "execution_count": 3, "id": "50f07854-971e-4aa9-9295-5bad0d995168", "metadata": {"tags": []}, "outputs": [{"data": {"text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://my-first-cluster-m.us-central1-f.c.striking-berm-457204-i1.internal:33365\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.3</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>PySparkShell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ", "text/plain": "<pyspark.sql.session.SparkSession at 0x7fe1baf53510>"}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": "spark"}, {"cell_type": "code", "execution_count": 4, "id": "927826c8-259a-4ace-a339-5c5a4616ee75", "metadata": {"tags": []}, "outputs": [], "source": "hdfs_path = '/data/customers500.csv'\nrdd = spark.sparkContext.textFile(hdfs_path)"}, {"cell_type": "code", "execution_count": 16, "id": "f9f0c9ab-1c5d-401e-a1fc-9c5d4397cd84", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "header = rdd.first()\nrdd_no_header = rdd.filter(lambda row : (row != header)).map(lambda row : row.split(','))"}, {"cell_type": "code", "execution_count": 17, "id": "a5f4651f-dcfa-4f57-9678-447edeb2bbb6", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "['218680',\n 'Customer_218680',\n 'Mumbai',\n 'Delhi',\n 'India',\n '2023-05-25',\n 'False']"}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": "rdd_no_header.first()"}, {"cell_type": "markdown", "id": "89550a5d-90da-4202-9844-a439b8bb50d6", "metadata": {}, "source": "## reduceByKey()"}, {"cell_type": "code", "execution_count": 20, "id": "85e6c569-9c24-4df7-b01d-05e40e1a33bb", "metadata": {"tags": []}, "outputs": [], "source": "reduced_by_rdd = rdd_no_header.map(lambda row : (row[2], 1)).reduceByKey(lambda x, y : (x+y))"}, {"cell_type": "code", "execution_count": 21, "id": "1077da78-aec1-4aae-9cc7-813c313922e5", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "[('Mumbai', 2097),\n ('Hyderabad', 2110),\n ('Pune', 2058),\n ('Delhi', 2053),\n ('Bangalore', 2076),\n ('Kolkata', 2036),\n ('Chennai', 2051),\n ('Ahmedabad', 2066)]"}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": "reduced_by_rdd.collect()"}, {"cell_type": "code", "execution_count": 34, "id": "cd995baf-eec6-4290-9ba6-95592c35af4f", "metadata": {"tags": []}, "outputs": [], "source": "#data written - 494.0 B"}, {"cell_type": "markdown", "id": "e405238f-e2ea-4bed-8b5c-a3727f66b6db", "metadata": {}, "source": "## groupByKey()"}, {"cell_type": "code", "execution_count": 28, "id": "2e789e4a-36a0-4d64-8ed3-28ff5bdc5df9", "metadata": {"tags": []}, "outputs": [], "source": "grouped_by_key = rdd_no_header.map(lambda row : (row[2], 1)).groupByKey()"}, {"cell_type": "code", "execution_count": 23, "id": "07362307-8661-441d-87f1-41d35e77c0c7", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "[('Mumbai', <pyspark.resultiterable.ResultIterable at 0x7fe1b958d450>),\n ('Hyderabad', <pyspark.resultiterable.ResultIterable at 0x7fe1b958dd10>),\n ('Pune', <pyspark.resultiterable.ResultIterable at 0x7fe1b958d2d0>),\n ('Delhi', <pyspark.resultiterable.ResultIterable at 0x7fe1ab4ad190>),\n ('Bangalore', <pyspark.resultiterable.ResultIterable at 0x7fe1bad5e710>),\n ('Kolkata', <pyspark.resultiterable.ResultIterable at 0x7fe1b9576210>),\n ('Chennai', <pyspark.resultiterable.ResultIterable at 0x7fe1b958ee50>),\n ('Ahmedabad', <pyspark.resultiterable.ResultIterable at 0x7fe1ab40d3d0>)]"}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": "grouped_by_key.collect()"}, {"cell_type": "code", "execution_count": 29, "id": "0d91b38c-a62c-49a3-b9eb-bd4f9c4f1323", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "('Mumbai', <pyspark.resultiterable.ResultIterable at 0x7fe1ab342310>)"}, "execution_count": 29, "metadata": {}, "output_type": "execute_result"}], "source": "grouped_by_key.first()"}, {"cell_type": "code", "execution_count": 32, "id": "0ce48f0b-78af-45d5-b9c0-db3926777077", "metadata": {"tags": []}, "outputs": [], "source": "count = grouped_by_key.map(lambda row : (row[0], len(row[1])))"}, {"cell_type": "code", "execution_count": 33, "id": "c3698df9-f9d5-4aee-835e-218f0e5bd02a", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "[('Mumbai', 2097),\n ('Hyderabad', 2110),\n ('Pune', 2058),\n ('Delhi', 2053),\n ('Bangalore', 2076),\n ('Kolkata', 2036),\n ('Chennai', 2051),\n ('Ahmedabad', 2066)]"}, "execution_count": 33, "metadata": {}, "output_type": "execute_result"}], "source": "count.collect()"}, {"cell_type": "code", "execution_count": null, "id": "c994ab52-61cd-4499-b9e1-a79fd11aa3bd", "metadata": {}, "outputs": [], "source": "#data written - 698.0 B"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}