{"cells": [{"cell_type": "code", "execution_count": 1, "id": "035ab694-a09a-4d9f-8d5a-30dae5d0f4b8", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/05/29 04:04:54 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('RDD Operation').getOrCreate()"}, {"cell_type": "code", "execution_count": 2, "id": "9cddd7f2-e78a-4356-a56c-ec107cd4ed9d", "metadata": {"tags": []}, "outputs": [], "source": "cust_data = [\n    \"customer_id,name,city,state,country,registration_date,is_active\",\n    \"0,Customer_0,Pune,Maharashtra,India,2023-06-29,False\",\n    \"1,Customer_1,Bangalore,Tamil Nadu,India,2023-12-07,True\",\n    \"2,Customer_2,Hyderabad,Gujarat,India,2023-10-27,True\",\n    \"3,Customer_3,Bangalore,Karnataka,India,2023-10-17,False\",\n    \"4,Customer_4,Ahmedabad,Karnataka,India,2023-03-14,False\",\n    \"5,Customer_5,Hyderabad,Karnataka,India,2023-07-28,False\",\n]"}, {"cell_type": "code", "execution_count": 3, "id": "9796ef2e-c908-453d-9cb1-f52cd550f6d3", "metadata": {"tags": []}, "outputs": [], "source": "rdd = spark.sparkContext.parallelize(cust_data)"}, {"cell_type": "code", "execution_count": null, "id": "4084cea8-8606-4326-a510-4c3dd8784171", "metadata": {"tags": []}, "outputs": [], "source": "header = rdd.first()\nheader"}, {"cell_type": "code", "execution_count": null, "id": "2d6d24cb-15d1-429b-8cfd-af2b06c255a5", "metadata": {"tags": []}, "outputs": [], "source": "data_rdd = rdd.filter(lambda row : row != header)\ndata_rdd.collect()"}, {"cell_type": "code", "execution_count": 17, "id": "e045d45c-ab00-4648-b4d5-c5c3dd0a75fb", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "[['0', 'Customer_0', 'Pune', 'Maharashtra', 'India', '2023-06-29', 'False'],\n ['1', 'Customer_1', 'Bangalore', 'Tamil Nadu', 'India', '2023-12-07', 'True'],\n ['2', 'Customer_2', 'Hyderabad', 'Gujarat', 'India', '2023-10-27', 'True'],\n ['3', 'Customer_3', 'Bangalore', 'Karnataka', 'India', '2023-10-17', 'False'],\n ['4', 'Customer_4', 'Ahmedabad', 'Karnataka', 'India', '2023-03-14', 'False'],\n ['5', 'Customer_5', 'Hyderabad', 'Karnataka', 'India', '2023-07-28', 'False']]"}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": "parsed_rdd = data_rdd.map(lambda row : row.split(','))\nparsed_rdd.collect()"}, {"cell_type": "code", "execution_count": 18, "id": "ec5cc770-938c-4af5-a7e8-3b88735e4c36", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "[('Pune', 1), ('Hyderabad', 2), ('Bangalore', 2), ('Ahmedabad', 1)]"}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": "#reduceByKey() - combines values for each key using an associative reduce function => transformation\ncust_per_city1 = parsed_rdd.map(lambda row : (row[2],1)).reduceByKey(lambda x,y : x+y)\ncust_per_city1.collect()"}, {"cell_type": "code", "execution_count": 19, "id": "7b984d30-91aa-4f64-a586-c7b3c7469056", "metadata": {"tags": []}, "outputs": [], "source": "spark.stop()"}, {"cell_type": "code", "execution_count": null, "id": "2da1b353-1fa1-4ec4-bcc0-468806e3e727", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}